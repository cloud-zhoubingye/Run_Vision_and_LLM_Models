{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFbUpH8elWQ7"
   },
   "source": [
    "# **Part 1: Run MobileNet on GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoNr0MWd5e5m"
   },
   "source": [
    "In this tutorial, we will explore how to train a neural network with PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoBtxdvR5lwM"
   },
   "source": [
    "### Setup (5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oLGv2RjLYh2"
   },
   "source": [
    "We will first install a few packages that will be used in this tutorial and also define the path of CUDA library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3r7Sl2cG7nZF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ϵͳ�Ҳ���ָ����·����\n",
      "ϵͳ�Ҳ���ָ����·����\n",
      "ϵͳ�Ҳ���ָ����·����\n",
      "ϵͳ�Ҳ���ָ����·����\n"
     ]
    }
   ],
   "source": [
    "!pip install torchprofile 1>/dev/null\n",
    "!ldconfig /usr/lib64-nvidia 2>/dev/null\n",
    "!pip install onnx 1>/dev/null\n",
    "!pip install onnxruntime 1>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYgp0au_LeAd"
   },
   "source": [
    "We will then import a few libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "I3uAhaCSlFrK"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "D-nNU83gqm9U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1Yx0rDUK5fx"
   },
   "source": [
    "To ensure the reproducibility, we will control the seed of random generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "j_l1wEdeHOlu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26f0553c230>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzMCWN0aJNvl"
   },
   "source": [
    "We must decide the HYPER-parameter before training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AyLHUYWZJNCJ"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "# TODO:\n",
    "# Decide your own hyper-parameters\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.1\n",
    "NUM_EPOCH = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7Y0sLyajGAu"
   },
   "source": [
    "### Data  (5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAbL_li0KPsz"
   },
   "source": [
    "In this lab, we will use CIFAR-10 as our target dataset. This dataset contains images from 10 classes, where each image is of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PO2mP2GytNl"
   },
   "source": [
    "Before using the data as input, we can do data pre-processing with transform function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Pqhy8EJSjJfp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar10\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m dataset \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m---> 14\u001b[0m   dataset[split] \u001b[38;5;241m=\u001b[39m \u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/cifar10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:66\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:140\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\site-packages\\torchvision\\datasets\\utils.py:395\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    393\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 395\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    397\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\site-packages\\torchvision\\datasets\\utils.py:132\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[1;32m--> 132\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\site-packages\\torchvision\\datasets\\utils.py:28\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[1;34m(url, filename, chunk_size)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_urlretrieve\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, filename: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath], chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser-Agent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mUSER_AGENT\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m response\u001b[38;5;241m.\u001b[39mread(chunk_size):\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\urllib\\request.py:515\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    512\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    514\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 515\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    518\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\urllib\\request.py:532\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    531\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 532\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    533\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\urllib\\request.py:1392\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m   1347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m-> 1348\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1350\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\http\\client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32md:\\Applications\\Conda\\MiniConda\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "# Resize images to 224x224, i.e., the input image size of MobileNet,\n",
    "# Convert images to PyTorch tensors, and\n",
    "# Normalize the images with mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "transform = torchvision.transforms.Compose([\n",
    "  torchvision.transforms.Resize((224, 224)),\n",
    "  torchvision.transforms.ToTensor(),\n",
    "  torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "dataset = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "  dataset[split] = CIFAR10(\n",
    "    root=\"data/cifar10\",\n",
    "    train=(split == \"train\"),\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkigVqADNeIN"
   },
   "source": [
    "To train a neural network, we will need to feed data in batches.\n",
    "\n",
    "We create data loaders with the batch size determined previously in setup section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4axnQCtnks_s"
   },
   "outputs": [],
   "source": [
    "dataflow = {}\n",
    "for split in ['train', 'test']:\n",
    "  dataflow[split] = DataLoader(\n",
    "    dataset[split],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=(split == 'train'),\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5G1Lf6hOLGT"
   },
   "source": [
    "We can print the data type and shape from the training data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReP2g9pD6ppI"
   },
   "outputs": [],
   "source": [
    "for inputs, targets in dataflow[\"train\"]:\n",
    "  print(f\"[inputs] dtype: {inputs.dtype}, shape: {inputs.shape}\")\n",
    "  print(f\"[targets] dtype: {targets.dtype}, shape: {targets.shape}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPAEVnixjwb7"
   },
   "source": [
    "### Model (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFr1Js3-e3rJ"
   },
   "source": [
    "In this tutorial, we will import MobileNet provided by torchvision, and use the pre-trained weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNLdS_UQjyBf"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Load pre-trained MobileNetV2\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "\n",
    "model = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WB2X6czdV0px"
   },
   "source": [
    "You should observe that the output dimension of the classifier does not match the number of cleasses in CIFAR-10.\n",
    "\n",
    "Now change the output dimension of the classifer to number of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nmo4u51gVzXz"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Change the output dimension of the classifer to number of classes\n",
    "in_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_features, NUM_CLASSES)\n",
    "print(model)\n",
    "\n",
    "# Send the model from cpu to gpu\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"Cuda is not available.\")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEtm9nswWT1z"
   },
   "source": [
    "Now the output dimension of the classifer matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_RcCWoQ8Kp1"
   },
   "source": [
    "As this course focuses on efficiency, we will then inspect its model size and (theoretical) computation cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd4Xu-vMyz39"
   },
   "source": [
    "* The model size can be estimated by the number of trainable parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gTfqC0B7Uzi"
   },
   "outputs": [],
   "source": [
    "num_params = 0\n",
    "for param in model.parameters():\n",
    "  if param.requires_grad:\n",
    "    num_params += param.numel()\n",
    "print(\"#Params:\", num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAZoIKIbzLa4"
   },
   "source": [
    "* The computation cost can be estimated by the number of [multiply–accumulate operations (MACs)](https://en.wikipedia.org/wiki/Multiply–accumulate_operation) using [TorchProfile](https://github.com/zhijian-liu/torchprofile), we will further use this profiling tool in the future labs ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKVmyWCN7qpp"
   },
   "outputs": [],
   "source": [
    "num_macs = profile_macs(model, torch.zeros(1, 3, 224, 224).cuda())\n",
    "print(\"#MACs:\", num_macs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYkqpfejzxwq"
   },
   "source": [
    "This model has 2.2M parameters and requires 306M MACs for inference. We will work together in the next few labs to improve its efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjDsY9_KkIjZ"
   },
   "source": [
    "### Optimization (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRg_5KeKLHPj"
   },
   "source": [
    "As we are working on a classification problem, we will apply [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) as our loss function to optimize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-K0DEhGKkKfF"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Apply cross entropy as our loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3H8YniYeLIdg"
   },
   "source": [
    "We should decide an optimizer for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXANib83LATH"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Choose an optimizer.\n",
    "# 使用Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9X8SiWYLJw2"
   },
   "source": [
    "(Optional) We can apply a learning rate scheduler during the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mJU5aw8KrVX"
   },
   "outputs": [],
   "source": [
    "# TODO(optional):\n",
    "# 余弦退火\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2UFRbRYly50"
   },
   "source": [
    "### Training (25%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpHZJpjR7Wy3"
   },
   "source": [
    "We first define the function that optimizes the model for one batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79GKx_oVl09b"
   },
   "outputs": [],
   "source": [
    "def train_one_batch(\n",
    "  model: nn.Module,\n",
    "  criterion: nn.Module,\n",
    "  optimizer,\n",
    "  inputs: torch.Tensor,\n",
    "  targets: torch.Tensor,\n",
    "  scheduler\n",
    ") -> None:\n",
    "\n",
    "    # TODO:\n",
    "    # Step 1: Reset the gradients (from the last iteration)\n",
    "    optimizer.zero_grad()\n",
    "    # Step 2: Forward inference\n",
    "    output = model(inputs)\n",
    "    # Step 3: Calculate the loss\n",
    "    loss = criterion(output, targets)\n",
    "    # Step 4: Backward propagation\n",
    "    loss.backward()\n",
    "    # Step 5: Update optimizer\n",
    "    optimizer.step()\n",
    "    # (Optional Step 6: scheduler)\n",
    "    scheduler.step()\n",
    "    \n",
    "    return loss.cpu().detach().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kePTCanalUE"
   },
   "source": [
    "We then define the training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SWx96SGajDR"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    dataflow: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer,\n",
    "    scheduler\n",
    "):\n",
    "\n",
    "  model.train()\n",
    "  n_data = 0\n",
    "  total_loss = 0.0\n",
    "  for inputs, targets in tqdm(dataflow, desc='train', leave=False):\n",
    "    \n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Call train_one_batch function\n",
    "    loss_batch = train_one_batch(model, criterion, optimizer, inputs, targets, scheduler)\n",
    "    total_loss += loss_batch\n",
    "    n_data += 1\n",
    "    \n",
    "  return total_loss / n_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGaYWFFCbD32"
   },
   "source": [
    "Last, we define the evaluation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXVXHqimbOIo"
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataflow: DataLoader\n",
    ") -> float:\n",
    "\n",
    "    model.eval()\n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(dataflow, desc=\"eval\", leave=False):\n",
    "            # TODO:\n",
    "            # Step 1: Move the data from CPU to GPU\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            # Step 2: Forward inference\n",
    "            output = model(inputs)\n",
    "            # Step 3: Convert logits to class indices (predicted class)\n",
    "            predicts = output.argmax(dim=1)\n",
    "            # Update metrics\n",
    "            num_samples += targets.size(0)\n",
    "            num_correct += (predicts == targets).sum()\n",
    "\n",
    "    return (num_correct / num_samples * 100).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWCOYuj5cNg3"
   },
   "source": [
    "With training and evaluation functions, we can finally start training the model!\n",
    "\n",
    "If the training is done properly, the accuracy should simply reach higher than 0.925:\n",
    "\n",
    "***Please screenshot the output model accuracy, hand in as YourID_acc_1.png***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "czZObK4OcPD-"
   },
   "outputs": [],
   "source": [
    "bar = tqdm(range(1, NUM_EPOCH + 1))\n",
    "for epoch_num in bar:\n",
    "  loss_epoch = train(model, dataflow[\"train\"], criterion, optimizer, scheduler)\n",
    "  acc = evaluate(model, dataflow[\"test\"])\n",
    "  bar.set_postfix_str(f\"loss: {loss_epoch:.6f}, acc: {acc:.4f}\")\n",
    "\n",
    "print(f\">>> Final accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ao7C2ZSudE0o"
   },
   "source": [
    "Save the weight of the model as \"model.pt\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQrW_B-bcygR"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Save the model weight\n",
    "torch.save(model.state_dict(), \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6pbapVjdTG3"
   },
   "source": [
    "You will find \"model.pt\" in the current folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqwrM470RNoO"
   },
   "source": [
    "### Export Model (5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHpw1pWF6d1c"
   },
   "source": [
    "We can also save the model weight in [ONNX Format](https://pytorch.org/docs/stable/onnx_torchscript.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yd8oq4-O6kla"
   },
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "\n",
    "# TODO:\n",
    "# Specify the input shape\n",
    "\n",
    "onnx_path = 'model.onnx'\n",
    "\n",
    "# TODO:\n",
    "# Export the model to ONNX format\n",
    "dummy_input = torch.randn(1, 3, 224, 224).cuda()\n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]\n",
    "torch.onnx.export(model, dummy_input, onnx_path, verbose=True, input_names=input_names, output_names=output_names)\n",
    "\n",
    "print(f\"Model exported to {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLnLCIuv7M46"
   },
   "source": [
    "In onnx format, we can observe the model structure using [Netron](https://netron.app/).\n",
    "\n",
    "***Please download the model structure, hand in as YourID_onnx.png.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QjgTo0GduJx"
   },
   "source": [
    "### Inference (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEH0zddHdzH-"
   },
   "source": [
    "Load the saved model weight:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i28yt-XOdweL"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Step 1: Get the model structure (mobilenet_v2 and the classifier)\n",
    "loaded_model = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "in_features = loaded_model.classifier[1].in_features\n",
    "loaded_model.classifier[1] = nn.Linear(in_features, NUM_CLASSES)\n",
    "\n",
    "# Step 2: Load the model weight from \"model.pt\".\n",
    "loaded_model.load_state_dict(torch.load(\"model.pt\"))\n",
    "\n",
    "# Step 3: Send the model from cpu to gpu\n",
    "loaded_model = loaded_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEaZWcuheRFv"
   },
   "source": [
    "Run inference with the loaded model weight and check the accuracy\n",
    "\n",
    "***Please screenshot the output model accuracy, hand in as YourID_acc_2.png***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dMRsPgGeYe6"
   },
   "outputs": [],
   "source": [
    "acc = evaluate(loaded_model, dataflow[\"test\"])\n",
    "print(f\"accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytdLy6EIfoeT"
   },
   "source": [
    "If the accurracy is the same as the accuracy before saved, you have completed PART 1.\n",
    "\n",
    "Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni0FnXXHcgXa"
   },
   "source": [
    "# **Part 2: LLM with torch.compile**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiOzZkitfkmM"
   },
   "source": [
    "In part 2, we will compare the inference speed of the LLM whether we use torch.compile.\n",
    "\n",
    "```torch.compile``` is a new feature in PyTorch 2.0.\n",
    "\n",
    "The following tutorial will help you get to know the usage.\n",
    "\n",
    "[Introduction to torch.compile](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html)\n",
    "\n",
    "We will choose ```Llama-3.2-1B-Instruct``` as our LLM model.\n",
    "\n",
    "Make sure you have access to llama before starting Part 2.\n",
    "\n",
    "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bu-ihO_RiaVM"
   },
   "source": [
    "### Loading LLM (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3LSb5aoiodV"
   },
   "source": [
    "We will first install huggingface and login with your token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "id": "7EhC4kl0_CUf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: huggingface_hub[cli] in d:\\applications\\conda\\miniconda\\lib\\site-packages (0.23.2)\n",
      "Collecting huggingface_hub[cli]\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ae/05/75b90de9093de0aadafc868bb2fa7c57651fd8f45384adf39bd77f63980d/huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Requirement already satisfied: filelock in d:\\applications\\conda\\miniconda\\lib\\site-packages (from huggingface_hub[cli]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\applications\\conda\\miniconda\\lib\\site-packages (from huggingface_hub[cli]) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\applications\\conda\\miniconda\\lib\\site-packages (from huggingface_hub[cli]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\applications\\conda\\miniconda\\lib\\site-packages (from huggingface_hub[cli]) (6.0.1)\n",
      "Requirement already satisfied: requests in d:\\applications\\conda\\miniconda\\lib\\site-packages (from huggingface_hub[cli]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\applications\\conda\\miniconda\\lib\\site-packages (from huggingface_hub[cli]) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\applications\\conda\\miniconda\\lib\\site-packages (from huggingface_hub[cli]) (4.11.0)\n",
      "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ce/ff/3b59672c47c6284e8005b42e84ceba13864aa0f39f067c973d1af02f5d91/InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8c/d7/8ff98376b1acc4503253b685ea09981697385ce344d4e3935c2af49e044d/pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in d:\\applications\\conda\\miniconda\\lib\\site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.42)\n",
      "Requirement already satisfied: colorama in d:\\applications\\conda\\miniconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub[cli]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\applications\\conda\\miniconda\\lib\\site-packages (from requests->huggingface_hub[cli]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\applications\\conda\\miniconda\\lib\\site-packages (from requests->huggingface_hub[cli]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\applications\\conda\\miniconda\\lib\\site-packages (from requests->huggingface_hub[cli]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\applications\\conda\\miniconda\\lib\\site-packages (from requests->huggingface_hub[cli]) (2024.12.14)\n",
      "Requirement already satisfied: wcwidth in d:\\applications\\conda\\miniconda\\lib\\site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.13)\n",
      "Installing collected packages: pfzy, InquirerPy, huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.23.2\n",
      "    Uninstalling huggingface-hub-0.23.2:\n",
      "      Successfully uninstalled huggingface-hub-0.23.2\n",
      "Successfully installed InquirerPy-0.3.4 huggingface_hub-0.29.1 pfzy-0.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"huggingface_hub[cli]\"\n",
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUD-npfwki3T"
   },
   "source": [
    "We choose LLaMa 3.2 1B Instruct as our LLM model and load the pretrained model.\n",
    "\n",
    "Model ID: **\"meta-llama/Llama-3.2-1B-Instruct\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjCkbW_i8VUq"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# TODO:\n",
    "# Load the LLaMA 3.2 1B Instruct model\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained()\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1F8VBtODHX2"
   },
   "source": [
    "First we need to decide our prompt to feed into LLM and the maximum token length as well.\n",
    "\n",
    "You can also change the iteration times of testing for the following tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJMPtSLuCzCq"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Input prompt\n",
    "# You can change the prompt whatever you want, e.g. \"How to learn a new language?\", \"What is Edge AI?\"\n",
    "\n",
    "prompt = \"What is Edge AI?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "max_token_length = 512\n",
    "iter_times = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiHloHdRKaaY"
   },
   "source": [
    "### Inference with torch.compile (10%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWj3sD_PJL7Z"
   },
   "source": [
    "Let's define a timer function to compare the speed up of ```torch.compile```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNK4ukXZb631"
   },
   "outputs": [],
   "source": [
    "def timed(fn):\n",
    "  start = torch.cuda.Event(enable_timing=True)\n",
    "  end = torch.cuda.Event(enable_timing=True)\n",
    "  start.record()\n",
    "  result = fn()\n",
    "  end.record()\n",
    "  torch.cuda.synchronize()\n",
    "  return result, start.elapsed_time(end) / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4IDTZYbJxJj"
   },
   "source": [
    "After everything is set up, let's start!\n",
    "\n",
    "We first simply run the inference without ```torch.compile```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-u-fBCU-b7hS"
   },
   "outputs": [],
   "source": [
    "original_times = []\n",
    "\n",
    "# Timing without torch.compile\n",
    "for i in range(iter_times):\n",
    "  with torch.no_grad():\n",
    "    original_output, original_time = timed(lambda: model.generate(**inputs, max_length=max_token_length, pad_token_id=tokenizer.eos_token_id))\n",
    "  original_times.append(original_time)\n",
    "  print(f\"Time taken without torch.compile: {original_time} seconds\")\n",
    "\n",
    "# Decode the output\n",
    "output_text = tokenizer.decode(original_output[0], skip_special_tokens=True)\n",
    "print(f\"Output without torch.compile: {output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeVhUlk_K9La"
   },
   "source": [
    "Before using ```torch.compile```, we need to access the model's ```generation_config``` attribute and set the ```cache_implementation``` to \"static\".\n",
    "\n",
    "To use ```torch.compile```, we need to call ```torch.compile``` on the model to compile the forward pass with the static kv-cache.\n",
    "\n",
    "Reference: https://huggingface.co/docs/transformers/llm_optims?static-kv=basic+usage%3A+generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BQkTIDusb_7i"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000002CC7B6CA450>>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Applications\\Conda\\MiniConda\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 785, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Applications\\Conda\\MiniConda\\Lib\\threading.py\", line 1533, in enumerate\n",
      "    def enumerate():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# TODO:\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mcache_implementation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatic\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m compiled_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcompile(model)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Timing with torch.compile\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "compile_times = []\n",
    "\n",
    "# Remind that whenever you use torch.compile, you need to use torch._dynamo.reset() to clear all compilation caches and restores the system to its initial state.\n",
    "import torch._dynamo\n",
    "torch._dynamo.reset()\n",
    "\n",
    "# TODO:\n",
    "# Compile the model\n",
    "model.generation_config.cache_implementation = \"static\"\n",
    "compiled_model = torch.compile(model)\n",
    "\n",
    "# Timing with torch.compile\n",
    "for i in range(iter_times):\n",
    "  with torch.no_grad():\n",
    "    compile_output, compile_time = timed(lambda: compiled_model.generate(**inputs, max_length=max_token_length, pad_token_id=tokenizer.eos_token_id))\n",
    "  compile_times.append(compile_time)\n",
    "  print(f\"Time taken with torch.compile: {compile_time} seconds\")\n",
    "\n",
    "# Decode output\n",
    "output_text = tokenizer.decode(compile_output[0], skip_special_tokens=True)\n",
    "print(f\"\\nOutput with torch.compile: {output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFZMBADDTo5T"
   },
   "source": [
    "We can easily observe that after the first inference, the inference time drops a lot!\n",
    "\n",
    "Below code can tell you how much faster did ```torch.compile``` did.\n",
    "\n",
    "***Please screenshot the inference time and speedup below, hand in as YourID_speedup.png***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPbqAgo6P7et"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "original_med = np.median(original_times)\n",
    "compile_med = np.median(compile_times)\n",
    "speedup = original_med / compile_med\n",
    "print(f\"Original median: {original_med},\\nCompile median: {compile_med},\\nSpeedup: {speedup}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXdb901VmrZS"
   },
   "source": [
    "You've finished part 2.\n",
    "\n",
    "Congratulations!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
